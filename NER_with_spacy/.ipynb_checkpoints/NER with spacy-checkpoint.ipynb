{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "reduced-assault",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "casual-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-lesson",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-discount",
   "metadata": {},
   "source": [
    "Data source: https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "wired-conditions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/ner_dataset.csv')\n",
    "df['Sentence #'] = df['Sentence #'].ffill()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "meaningful-furniture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040097eeaed44c3e8f0522a644d91091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363b5318b5af42c89e3944196a573bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4795 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_spacy_file(df, sentences, train_test=\"train\"):\n",
    "    nlp = spacy.blank(\"en\") # load a new spacy model\n",
    "    db = DocBin() # create a DocBin obje\n",
    "    for i in tqdm(sentences):\n",
    "        df2 = df[df['Sentence #']==i]\n",
    "        word_length = df2['Word'].apply(lambda x: len(x)+1)\n",
    "        df2['End'] = word_length.cumsum()-1\n",
    "        df2['Start'] = df2['End']-word_length+1\n",
    "\n",
    "        # get content\n",
    "        content = ' '.join([df['Word'][j] for j in df2.index])\n",
    "        doc = nlp.make_doc(content)\n",
    "\n",
    "        # get entities\n",
    "        ents = []\n",
    "        df2 = df2[df2['Tag'] != 'O']\n",
    "        for index, row in df2.iterrows():\n",
    "            span = doc.char_span(row['Start'], row['End'], label=row['Tag'], alignment_mode=\"contract\")\n",
    "            if span:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    db.to_disk(f\"./{train_test}.spacy\")\n",
    "\n",
    "train_pct = 0.8\n",
    "dev_pct = 0.1\n",
    "sentences = df['Sentence #'].unique()\n",
    "n = len(sentences)\n",
    "n_train = int(train_pct*n)\n",
    "n_dev = int(dev_pct*n)\n",
    "train_sentences = df['Sentence #'].unique()[:n_train]\n",
    "dev_sentences = df['Sentence #'].unique()[n_train:n_train+n_dev]\n",
    "get_spacy_file(df, train_sentences, 'train')\n",
    "get_spacy_file(df, dev_sentences, 'dev')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-anthropology",
   "metadata": {},
   "source": [
    "# Fill Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "handy-conviction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\r\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\r\n",
      "config.cfg\r\n",
      "You can now add your data and train your pipeline:\r\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-southeast",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fatty-graduation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2021-04-26 21:07:56,772] [INFO] Set up nlp object from config\n",
      "[2021-04-26 21:07:56,790] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-04-26 21:07:56,797] [INFO] Created vocabulary\n",
      "[2021-04-26 21:07:56,797] [INFO] Finished initializing nlp object\n",
      "[2021-04-26 21:08:31,612] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     57.59    0.00    0.00    0.00    0.00\n",
      "  0     200         82.50   3479.50   55.03   58.81   51.69    0.55\n",
      "  0     400        272.74   2419.22   69.91   70.38   69.45    0.70\n",
      "  0     600        242.02   2463.52   74.89   75.21   74.57    0.75\n",
      "  0     800        375.82   2787.09   77.27   80.01   74.72    0.77\n",
      "  0    1000        386.50   3389.05   78.40   78.84   77.96    0.78\n",
      "  0    1200        453.45   3712.78   79.20   80.62   77.82    0.79\n",
      "  0    1400        514.08   4356.35   81.74   81.85   81.63    0.82\n",
      "  0    1600        598.96   5109.59   82.59   83.61   81.60    0.83\n",
      "  0    1800        723.35   6092.19   82.33   82.12   82.55    0.82\n",
      "  0    2000        863.80   7039.46   83.28   84.20   82.39    0.83\n",
      "  0    2200       1038.03   8335.31   83.68   84.00   83.36    0.84\n",
      "  1    2400       1222.71   8902.29   83.70   83.82   83.58    0.84\n",
      "  1    2600       1333.18   8705.14   83.77   83.96   83.58    0.84\n",
      "  1    2800       1337.46   8696.19   84.23   85.23   83.25    0.84\n",
      "  1    3000       1380.00   8704.70   84.57   85.13   84.02    0.85\n",
      "  2    3200       1335.52   8318.02   84.51   84.59   84.42    0.85\n",
      "  2    3400       1391.30   7439.25   84.79   85.07   84.52    0.85\n",
      "  2    3600       1473.11   7922.40   84.11   84.00   84.22    0.84\n",
      "  2    3800       1503.96   7885.80   84.69   85.12   84.26    0.85\n",
      "  2    4000       1469.77   8047.45   84.51   84.18   84.84    0.85\n",
      "  3    4200       1478.53   6990.45   84.58   84.19   84.98    0.85\n",
      "  3    4400       1553.78   7042.11   84.73   85.11   84.35    0.85\n",
      "  3    4600       1579.37   7004.67   84.39   84.83   83.97    0.84\n",
      "  3    4800       1602.83   7380.19   84.93   85.02   84.85    0.85\n",
      "  4    5000       1601.28   6701.22   84.52   84.76   84.28    0.85\n",
      "  4    5200       1652.86   6629.21   85.09   85.14   85.04    0.85\n",
      "  4    5400       1797.99   6706.35   84.88   84.95   84.80    0.85\n",
      "  4    5600       1719.34   6736.03   84.75   85.20   84.30    0.85\n",
      "  5    5800       1671.88   6534.80   84.89   85.64   84.15    0.85\n",
      "  5    6000       1791.92   6067.45   84.76   85.36   84.17    0.85\n",
      "  5    6200       1874.37   6177.71   84.84   84.78   84.90    0.85\n",
      "  5    6400       1954.44   6324.46   84.96   86.06   83.88    0.85\n",
      "  5    6600       1835.63   6555.77   84.85   84.72   84.98    0.85\n",
      "  6    6800       1787.65   5680.56   84.81   85.84   83.80    0.85\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./dev.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-marine",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "brazilian-mongolia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e99c556faba4d18b71585f09efff36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4797 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(R\"./output/model-best\")\n",
    "type1_error, type2_error, n_words = 0, 0, 0\n",
    "test_sentences = df['Sentence #'].unique()[n_train+n_dev:]\n",
    "for i in tqdm(test_sentences):\n",
    "    df2 = df[df['Sentence #']==i]\n",
    "    sentence = ' '.join([df2['Word'][j] for j in df2.index])\n",
    "    df2 = df2[df2['Tag'] != 'O']\n",
    "    n_words += len(df2)\n",
    "    \n",
    "    # truth\n",
    "    words = df2['Word'].values\n",
    "    tags = df2['Tag'].values\n",
    "    truths = []\n",
    "    for j in range(len(words)):\n",
    "        truths.append((words[j], tags[j]))\n",
    "    \n",
    "    # predict\n",
    "    doc = nlp(sentence)\n",
    "    predictions = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "    # type 1 error\n",
    "    for prediction in predictions:\n",
    "        if prediction not in truths:\n",
    "            type1_error += 1\n",
    "    \n",
    "    # type 2 error\n",
    "    for truth in truths:\n",
    "        if truth not in predictions:\n",
    "            type2_error += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "domestic-diesel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 1 error: 0.14954776359806715\n",
      "Type 2 error: 0.15208772147193655\n"
     ]
    }
   ],
   "source": [
    "type1_error = type1_error/n_words\n",
    "type2_error = type2_error/n_words\n",
    "print('Type 1 error: {}'.format(type1_error))\n",
    "print('Type 2 error: {}'.format(type2_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "threatened-linux",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>944610</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>At</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944611</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944612</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>Group</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944613</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944614</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>Eight</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944615</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>summit</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944616</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944617</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944618</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944619</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944620</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>Prime</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944621</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>Minister</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944622</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>Junichiro</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944623</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>Koizumi</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944624</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944625</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>he</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944626</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944627</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>outraged</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944628</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>by</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944629</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944630</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944631</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>attacks</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944632</th>\n",
       "      <td>Sentence: 43163</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sentence #       Word  POS    Tag\n",
       "944610  Sentence: 43163         At   IN      O\n",
       "944611  Sentence: 43163        the   DT      O\n",
       "944612  Sentence: 43163      Group  NNP  B-org\n",
       "944613  Sentence: 43163         of   IN  I-org\n",
       "944614  Sentence: 43163      Eight   CD  I-org\n",
       "944615  Sentence: 43163     summit   NN  I-org\n",
       "944616  Sentence: 43163         in   IN      O\n",
       "944617  Sentence: 43163   Scotland  NNP  B-geo\n",
       "944618  Sentence: 43163          ,    ,      O\n",
       "944619  Sentence: 43163   Japanese   JJ  B-gpe\n",
       "944620  Sentence: 43163      Prime  NNP  B-per\n",
       "944621  Sentence: 43163   Minister  NNP  I-per\n",
       "944622  Sentence: 43163  Junichiro  NNP  I-per\n",
       "944623  Sentence: 43163    Koizumi  NNP  I-per\n",
       "944624  Sentence: 43163       said  VBD      O\n",
       "944625  Sentence: 43163         he  PRP      O\n",
       "944626  Sentence: 43163         is  VBZ      O\n",
       "944627  Sentence: 43163   outraged  VBN      O\n",
       "944628  Sentence: 43163         by   IN      O\n",
       "944629  Sentence: 43163        the   DT      O\n",
       "944630  Sentence: 43163     London  NNP  B-geo\n",
       "944631  Sentence: 43163    attacks  NNS      O\n",
       "944632  Sentence: 43163          .    .      O"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize\n",
    "df2 = df[df['Sentence #']==test_sentences[0]]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cleared-routine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">At the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Group\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-org</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    of\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-org</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Eight\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-org</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    summit\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-org</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Scotland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-geo</span>\n",
       "</mark>\n",
       " , \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Japanese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-gpe</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Prime\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-per</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Minister\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-per</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Junichiro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-per</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Koizumi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-per</span>\n",
       "</mark>\n",
       " said he is outraged by the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    London\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-geo</span>\n",
       "</mark>\n",
       " attacks .</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = ' '.join([df2['Word'][j] for j in df2.index])\n",
    "doc = nlp(sentence)\n",
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
